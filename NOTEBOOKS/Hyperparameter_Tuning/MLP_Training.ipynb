{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BrL2eGW5gK4p"
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "# Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NpSyW6ggqUwA"
   },
   "source": [
    "Import libraries and dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "plgMWQ83mqE1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\python312\\lib\\site-packages (1.5.0)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\python312\\lib\\site-packages (from scikit-learn) (1.26.1)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\python312\\lib\\site-packages (from scikit-learn) (1.11.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\python312\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\python312\\lib\\site-packages (from scikit-learn) (3.5.0)\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "tsGMw5QUpmpp"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "url = 'https://drive.google.com/file/d/1-0exaTj91_tdZ8IxIH0esLd1ty0Uyd6I/view?usp=sharing'\n",
    "url='https://drive.google.com/uc?id=' + url.split('/')[-2]\n",
    "df1 = pd.read_csv(url)\n",
    "\n",
    "dir = '/content/drive/MyDrive/CS180/Project/CS180_Project_cbragunton_jtderez/IMPLEMENTATION'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1yPTft6XpwIg",
    "outputId": "8c0823dc-1388-46de-a996-98fd018a0cc6"
   },
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')\n",
    "\n",
    "#%cd /content/drive/MyDrive/CS180/Project/CS180_Project_cbragunton_jtderez/IMPLEMENTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Kt71OmGyfmWl",
    "outputId": "1e8a39f1-ba7d-4343-f1ce-4041f33a2f23"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Global_Sales  Critic_Score  Critic_Count  User_Score  User_Count   highest  \\\n",
      "0         82.53          76.0          51.0         8.0       322.0  NA_Sales   \n",
      "1         35.52          82.0          73.0         8.3       709.0  NA_Sales   \n",
      "2         32.77          80.0          73.0         8.0       192.0  NA_Sales   \n",
      "3         29.80          89.0          65.0         8.5       431.0  NA_Sales   \n",
      "4         28.92          58.0          41.0         6.6       129.0  NA_Sales   \n",
      "5         28.32          87.0          80.0         8.4       594.0  NA_Sales   \n",
      "6         23.21          91.0          64.0         8.6       464.0  NA_Sales   \n",
      "7         22.70          80.0          63.0         7.7       146.0  NA_Sales   \n",
      "8         21.81          61.0          45.0         6.3       106.0  NA_Sales   \n",
      "9         21.79          80.0          33.0         7.4        52.0  NA_Sales   \n",
      "\n",
      "        lowest  Platform_2600  Platform_3DO  Platform_3DS  ...  Developer_nan  \\\n",
      "0     JP_Sales            0.0           0.0           0.0  ...            0.0   \n",
      "1  Other_Sales            0.0           0.0           0.0  ...            0.0   \n",
      "2  Other_Sales            0.0           0.0           0.0  ...            0.0   \n",
      "3  Other_Sales            0.0           0.0           0.0  ...            0.0   \n",
      "4  Other_Sales            0.0           0.0           0.0  ...            0.0   \n",
      "5  Other_Sales            0.0           0.0           0.0  ...            0.0   \n",
      "6  Other_Sales            0.0           0.0           0.0  ...            0.0   \n",
      "7  Other_Sales            0.0           0.0           0.0  ...            0.0   \n",
      "8     JP_Sales            0.0           0.0           0.0  ...            0.0   \n",
      "9  Other_Sales            0.0           0.0           0.0  ...            0.0   \n",
      "\n",
      "   Rating_AO  Rating_E  Rating_E10+  Rating_EC  Rating_K-A  Rating_M  \\\n",
      "0        0.0       1.0          0.0        0.0         0.0       0.0   \n",
      "1        0.0       1.0          0.0        0.0         0.0       0.0   \n",
      "2        0.0       1.0          0.0        0.0         0.0       0.0   \n",
      "3        0.0       1.0          0.0        0.0         0.0       0.0   \n",
      "4        0.0       1.0          0.0        0.0         0.0       0.0   \n",
      "5        0.0       1.0          0.0        0.0         0.0       0.0   \n",
      "6        0.0       1.0          0.0        0.0         0.0       0.0   \n",
      "7        0.0       1.0          0.0        0.0         0.0       0.0   \n",
      "8        0.0       1.0          0.0        0.0         0.0       0.0   \n",
      "9        0.0       1.0          0.0        0.0         0.0       0.0   \n",
      "\n",
      "   Rating_RP  Rating_T  Rating_nan  \n",
      "0        0.0       0.0         0.0  \n",
      "1        0.0       0.0         0.0  \n",
      "2        0.0       0.0         0.0  \n",
      "3        0.0       0.0         0.0  \n",
      "4        0.0       0.0         0.0  \n",
      "5        0.0       0.0         0.0  \n",
      "6        0.0       0.0         0.0  \n",
      "7        0.0       0.0         0.0  \n",
      "8        0.0       0.0         0.0  \n",
      "9        0.0       0.0         0.0  \n",
      "\n",
      "[10 rows x 2379 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df1.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2H4Yr4DBh2xw"
   },
   "source": [
    "# Model 2: MLPClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1hd_kIEa3qEq"
   },
   "source": [
    "MLPClassifier from sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gqu7mXnUU8q0"
   },
   "source": [
    "Splitting Training, Validation, and Testing Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "YBziA2jmU8D7"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "X = df1.drop(['highest','lowest'], axis=1)\n",
    "lo = df1['lowest']\n",
    "hi = df1['highest']\n",
    "\n",
    "# Split data into train, validation, and test sets\n",
    "# for highest\n",
    "X_train, X_test, hi_train, hi_test = train_test_split(X, hi, test_size=0.2, random_state=427)\n",
    "\n",
    "#for lowest\n",
    "_, _, lo_train, lo_test = train_test_split(X, lo, test_size=0.2, random_state=427)\n",
    "\n",
    "scaler = MinMaxScaler(feature_range = (0,1))\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FdW_ui1_4mfB"
   },
   "source": [
    "Implementing Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SKF77JfV30pr",
    "outputId": "59f8c7b7-b239-4f69-eaa4-6946a4c92c38"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Highest Region\n",
      "Accuracy: 0.81\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    EU_Sales       0.67      0.66      0.66       275\n",
      "    JP_Sales       0.52      0.51      0.51        91\n",
      "    NA_Sales       0.87      0.88      0.88       989\n",
      " Other_Sales       0.33      0.10      0.15        10\n",
      "\n",
      "    accuracy                           0.81      1365\n",
      "   macro avg       0.60      0.54      0.55      1365\n",
      "weighted avg       0.80      0.81      0.81      1365\n",
      "\n",
      "Lowest Region\n",
      "Accuracy: 0.76\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    EU_Sales       0.56      0.53      0.54       207\n",
      "    JP_Sales       0.86      0.85      0.85       891\n",
      "    NA_Sales       0.66      0.61      0.64       132\n",
      " Other_Sales       0.56      0.69      0.62       135\n",
      "\n",
      "    accuracy                           0.76      1365\n",
      "   macro avg       0.66      0.67      0.66      1365\n",
      "weighted avg       0.76      0.76      0.76      1365\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# for highest\n",
    "mlp = MLPClassifier(random_state=427)\n",
    "mlp.fit(X_train, hi_train)\n",
    "hi_pred = mlp.predict(X_test)\n",
    "accuracy = accuracy_score(hi_test, hi_pred)\n",
    "report = classification_report(hi_test, hi_pred)\n",
    "print('Highest Region')\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "print(classification_report(hi_test, hi_pred))\n",
    "\n",
    "#for lowest\n",
    "mlp = MLPClassifier(random_state=427)\n",
    "mlp.fit(X_train, lo_train)\n",
    "lo_pred = mlp.predict(X_test)\n",
    "accuracy = accuracy_score(lo_test, lo_pred)\n",
    "report = classification_report(lo_test, lo_pred)\n",
    "print('Lowest Region')\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "print(classification_report(lo_test, lo_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t1Bfu6rdpDuG"
   },
   "source": [
    "Hyperparameter Tuning for MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 428
    },
    "id": "OvmenZ3cpEJG",
    "outputId": "0d45172e-a68e-4b0b-bdf2-d0225274d2e6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python312\\Lib\\site-packages\\sklearn\\experimental\\enable_hist_gradient_boosting.py:16: UserWarning: Since version 1.0, it is not needed to import enable_hist_gradient_boosting anymore. HistGradientBoostingClassifier and HistGradientBoostingRegressor are now stable and can be normally imported from sklearn.ensemble.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
      "Best parameters found:  {'solver': 'adam', 'max_iter': 1000, 'learning_rate_init': 0.001, 'learning_rate': 'invscaling', 'hidden_layer_sizes': (100,), 'alpha': 0.001, 'activation': 'relu'}\n",
      "Accuracy: 0.7619047619047619\n",
      "Lowest Region\n",
      "Accuracy: 0.76\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    EU_Sales       0.55      0.54      0.54       207\n",
      "    JP_Sales       0.86      0.85      0.85       891\n",
      "    NA_Sales       0.66      0.64      0.65       132\n",
      " Other_Sales       0.57      0.67      0.61       135\n",
      "\n",
      "    accuracy                           0.76      1365\n",
      "   macro avg       0.66      0.67      0.67      1365\n",
      "weighted avg       0.76      0.76      0.76      1365\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "\n",
    "# Initialize MLPClassifier\n",
    "lo_clf = MLPClassifier(random_state=427)\n",
    "\n",
    "# Define the hyperparameter distributions\n",
    "param_distributions = {\n",
    "    'hidden_layer_sizes': [(50,), (100,), (50,50), (100,50), (50, 100, 50)],\n",
    "    'activation': ['tanh', 'relu'],\n",
    "    'solver': ['lbfgs', 'sgd', 'adam'],\n",
    "    'alpha': [0.0001, 0.001, 0.01],\n",
    "    'learning_rate': ['invscaling', 'adaptive'],\n",
    "    'learning_rate_init': [0.001, 0.01, 0.1],\n",
    "    'max_iter': [1000]\n",
    "}\n",
    "\n",
    "# Initialize RandomizedSearchCV\n",
    "lo_random_search = RandomizedSearchCV(\n",
    "    estimator=lo_clf,\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=8,\n",
    "    cv=3,\n",
    "    scoring='f1_weighted',\n",
    "    verbose=2,\n",
    "    n_jobs=-1,\n",
    "    random_state=427\n",
    ")\n",
    "\n",
    "# Fit RandomizedSearchCV\n",
    "lo_random_search.fit(X_train, lo_train)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_lo_params = lo_random_search.best_params_\n",
    "print(\"Best parameters found: \", best_lo_params)\n",
    "\n",
    "# Initialize a new model with the best parameters\n",
    "best_lo_clf = MLPClassifier(**best_lo_params, random_state=427)\n",
    "\n",
    "# Fit the model\n",
    "best_lo_clf.fit(X_train, lo_train)\n",
    "\n",
    "# Predict on the test data\n",
    "lo_pred = best_lo_clf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy)\n",
    "accuracy = accuracy_score(lo_test, lo_pred)\n",
    "report = classification_report(lo_test, lo_pred)\n",
    "print('Lowest Region')\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "print('Classification Report:')\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "pSI1mwXQ3_uJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
      "Best parameters found:  {'solver': 'adam', 'max_iter': 1000, 'learning_rate_init': 0.001, 'learning_rate': 'adaptive', 'hidden_layer_sizes': (50,), 'alpha': 0.01, 'activation': 'relu'}\n",
      "Accuracy: 0.7611721611721611\n",
      "Highest Region\n",
      "Accuracy: 0.82\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    EU_Sales       0.73      0.64      0.68       275\n",
      "    JP_Sales       0.53      0.51      0.52        91\n",
      "    NA_Sales       0.87      0.91      0.89       989\n",
      " Other_Sales       0.25      0.10      0.14        10\n",
      "\n",
      "    accuracy                           0.82      1365\n",
      "   macro avg       0.60      0.54      0.56      1365\n",
      "weighted avg       0.81      0.82      0.81      1365\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize MLPClassifier\n",
    "hi_clf = MLPClassifier(random_state=427)\n",
    "\n",
    "# Define the hyperparameter distributions\n",
    "param_distributions = {\n",
    "    'hidden_layer_sizes': [(50,), (100,), (50,50), (100,50), (50, 100, 50)],\n",
    "    'activation': ['tanh', 'relu'],\n",
    "    'solver': ['lbfgs', 'sgd', 'adam'],\n",
    "    'alpha': [0.0001, 0.001, 0.01],\n",
    "    'learning_rate': ['invscaling', 'adaptive'],\n",
    "    'learning_rate_init': [0.001, 0.01, 0.1],\n",
    "    'max_iter': [1000]\n",
    "}\n",
    "\n",
    "# Initialize RandomizedSearchCV\n",
    "hi_random_search = RandomizedSearchCV(\n",
    "    estimator=lo_clf,\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=8,\n",
    "    cv=3,\n",
    "    scoring='f1_weighted',\n",
    "    verbose=2,\n",
    "    n_jobs=-1,\n",
    "    random_state=427\n",
    ")\n",
    "\n",
    "# Fit RandomizedSearchCV\n",
    "hi_random_search.fit(X_train, hi_train)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_hi_params = hi_random_search.best_params_\n",
    "print(\"Best parameters found: \", best_hi_params)\n",
    "\n",
    "# Initialize a new model with the best parameters\n",
    "best_hi_clf = MLPClassifier(**best_hi_params, random_state=427)\n",
    "\n",
    "# Fit the model\n",
    "best_hi_clf.fit(X_train, hi_train)\n",
    "\n",
    "# Predict on the test data\n",
    "hi_pred = best_hi_clf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy)\n",
    "accuracy = accuracy_score(hi_test, hi_pred)\n",
    "report = classification_report(hi_test, hi_pred)\n",
    "print('Highest Region')\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "print('Classification Report:')\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "yHRtEgXN4dk4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Highest_Region_MLPClassifier.pkl']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import Parallel, delayed\n",
    "import joblib\n",
    "\n",
    "#saving model\n",
    "joblib.dump(best_lo_clf, 'Lowest_Region_MLPClassifier.pkl')\n",
    "joblib.dump(best_hi_clf, 'Highest_Region_MLPClassifier.pkl')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
